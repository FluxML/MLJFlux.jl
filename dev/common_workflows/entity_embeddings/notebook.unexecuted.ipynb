{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Entity Embeddings with MLJFlux"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This demonstration is available as a Jupyter notebook or julia script\n",
    "[here](https://github.com/FluxML/MLJFlux.jl/tree/dev/docs/src/common_workflows/entity_embeddings)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Entity embedding is newer deep learning approach for categorical encoding introduced in 2016 by Cheng Guo and Felix Berkhahn.\n",
    "It employs a set of embedding layers to map each categorical feature into a dense continuous vector in a similar fashion to how they are employed in NLP architectures."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In MLJFlux, the `NeuralNetworkClassifier`, `NeuralNetworkRegressor`, and the `MultitargetNeuralNetworkRegressor`` can be trained and evaluated with heterogenous data (i.e., containing categorical features) because they have a built-in entity embedding layer.\n",
    "Moreover, they now offer a transform which encode the categorical features with the learnt embeddings to be used by an upstream machine learning model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook, we will explore how to use entity embeddings in MLJFlux models."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Pkg\n",
    "Pkg.activate(@__DIR__);\n",
    "Pkg.instantiate();"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Julia version** is assumed to be 1.10.*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Basic Imports"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using MLJ\n",
    "using Flux\n",
    "using Optimisers\n",
    "using CategoricalArrays\n",
    "using DataFrames\n",
    "using Random\n",
    "using Tables\n",
    "using ProgressMeter\n",
    "using Plots\n",
    "using ScientificTypes"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate some data"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X, y = make_blobs(1000, 2; centers=2, as_table=true, rng=40)\n",
    "X = DataFrame(X);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualize it"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X_class0 = X[y .== 1, :]\n",
    "X_class1 = X[y .== 2, :]\n",
    "\n",
    "p = plot()\n",
    "\n",
    "scatter!(p, X_class0[!, 1], X_class0[!, 2], markercolor=:blue, label=\"Class 0\")\n",
    "scatter!(p, X_class1[!, 1], X_class1[!, 2], markercolor=:red, label=\"Class 1\")\n",
    "\n",
    "title!(p, \"Classes in Different Colors\")\n",
    "xlabel!(\"Feature 1\")\n",
    "ylabel!(\"Feature 2\")\n",
    "\n",
    "plot(p)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's write a function that creates categorical features C1 and C2 from x1 and x2 in a meaningful way:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Random.seed!(40)\n",
    "generate_C1(x1) = (x1 > mean(X.x1) ) ? rand(['A', 'B'])  : rand(['C', 'D'])\n",
    "generate_C2(x2) = (x2 > mean(X.x2) ) ? rand(['X', 'Y'])  : rand(['Z'])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate C1 and C2 columns"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X[!, :C1] = [generate_C1(x) for x in X[!, :x1]]\n",
    "X[!, :C2] = [generate_C2(x) for x in X[!, :x2]]\n",
    "X[!, :R3] = rand(1000);  # A random continuous column."
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Form final dataset using categorical and continuous columns"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X = X[!, [:C1, :C2, :R3]];"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's also necessary to cast the categorical columns to the correct scientific type as the embedding layer\n",
    "will have an effect on the model if and only if categorical columns exist."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X = coerce(X, :C1 =>Multiclass, :C2 =>Multiclass);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split the data"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "(X_train, X_test), (y_train, y_test) = partition(\n",
    "\t(X, y),\n",
    "\t0.8,\n",
    "\tmulti = true,\n",
    "\tshuffle = true,\n",
    "\tstratify = y,\n",
    "\trng = Random.Xoshiro(41)\n",
    ");"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build MLJFlux Model"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "NeuralNetworkClassifier = @load NeuralNetworkClassifier pkg = MLJFlux\n",
    "\n",
    "\n",
    "clf = MLJFlux.NeuralNetworkBinaryClassifier(\n",
    "    builder = MLJFlux.Short(n_hidden = 5),\n",
    "    optimiser = Optimisers.Adam(0.01),\n",
    "    batch_size = 2,\n",
    "    epochs = 100,\n",
    "    acceleration = CUDALibs(),\n",
    "    embedding_dims =  Dict(:C1 => 2, :C2 => 2,),\n",
    ");"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice that we specified to embed each of the columns to 2D columns. By default, it uses `min(numfeats - 1, 10)`\n",
    "for the new dimensionality of any categorical feature."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train and evaluate"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "mach = machine(clf, X_train, y_train)\n",
    "\n",
    "fit!(mach, verbosity = 0)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get predictions on the training data"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "y_pred = predict_mode(mach, X_test)\n",
    "balanced_accuracy(y_pred, y_test)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice how the model has learnt to almost perfectly distinguish the classes and all the information\n",
    "has been in the categorical variables."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize the embedding space"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "mapping_matrices = MLJFlux.get_embedding_matrices(\n",
    "                fitted_params(mach).chain,\n",
    "                [1, 2],             # feature indices\n",
    "                [:C1, :C2],         # feature names (to assign to the indices)\n",
    "            )\n",
    "\n",
    "C1_basis = mapping_matrices[:C1]\n",
    "C2_basis = mapping_matrices[:C2]\n",
    "\n",
    "p1 = scatter(C1_basis[1, :], C1_basis[2, :],\n",
    "             title = \"C1 Basis Columns\",\n",
    "             xlabel = \"Column 1\",\n",
    "             ylabel = \"Column 2\",\n",
    "             label = \"C1 Columns\",\n",
    "             legend = :topright)\n",
    "\n",
    "p2 = scatter(C2_basis[1, :], C2_basis[2, :],\n",
    "             title = \"C2 Basis Columns\",\n",
    "             xlabel = \"Column 1\",\n",
    "             ylabel = \"Column 2\",\n",
    "             label = \"C2 Columns\",\n",
    "             legend = :topright)\n",
    "\n",
    "c1_cats = ['A', 'B', 'C', 'D']\n",
    "for (i, col) in enumerate(eachcol(C1_basis))\n",
    "    annotate!(p1, col[1] + 0.1, col[2] + 0.1, text(c1_cats[i], :black, 8))\n",
    "end\n",
    "\n",
    "c2_cats = ['X', 'Y', 'Z']\n",
    "for (i, col) in enumerate(eachcol(C2_basis))\n",
    "    annotate!(p2, col[1] + 0.1, col[2] + 0.1, text(string(c2_cats[i]), :black, 8))\n",
    "end\n",
    "\n",
    "plot(p1, p2, layout = (1, 2), size = (1000, 400))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, categories that were generated in a similar pattern were assigned similar vectors. In a dataset,\n",
    "where some columns have high cardinality, it's expected that some of the categories will exhibit similar patterns."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transform (embed) data"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X_tr = MLJ.transform(mach, X);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "This will transform each categorical value into its corresponding embedding vector. Continuous value will remain intact."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  },
  "kernelspec": {
   "name": "julia-1.11",
   "display_name": "Julia 1.11.1",
   "language": "julia"
  }
 },
 "nbformat": 4
}
