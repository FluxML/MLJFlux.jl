<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Spam Detection with RNNs · MLJFlux</title><meta name="title" content="Spam Detection with RNNs · MLJFlux"/><meta property="og:title" content="Spam Detection with RNNs · MLJFlux"/><meta property="twitter:title" content="Spam Detection with RNNs · MLJFlux"/><meta name="description" content="Documentation for MLJFlux."/><meta property="og:description" content="Documentation for MLJFlux."/><meta property="twitter:description" content="Documentation for MLJFlux."/><script data-outdated-warner src="../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../search_index.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script><link href="../../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,100;0,300;0,400;0,700;0,900;1,100;1,300;1,400;1,700;1,900&amp;family=Montserrat:ital,wght@0,100..900;1,100..900&amp;display=swap" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../../"><img src="../../../assets/logo.gif" alt="MLJFlux logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../../">MLJFlux</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../../">Introduction</a></li><li><input class="collapse-toggle" id="menuitem-2" type="checkbox"/><label class="tocitem" for="menuitem-2"><span class="docs-label">Interface</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../interface/Summary/">Summary</a></li><li><a class="tocitem" href="../../../interface/Builders/">Builders</a></li><li><a class="tocitem" href="../../../interface/Custom Builders/">Custom Builders</a></li><li><a class="tocitem" href="../../../interface/Classification/">Classification</a></li><li><a class="tocitem" href="../../../interface/Regression/">Regression</a></li><li><a class="tocitem" href="../../../interface/Multitarget Regression/">Multi-Target Regression</a></li><li><a class="tocitem" href="../../../interface/Image Classification/">Image Classification</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">Common Workflows</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../common_workflows/incremental_training/notebook/">Incremental Training</a></li><li><a class="tocitem" href="../../../common_workflows/entity_embeddings/notebook/">Entity Embeddings</a></li><li><a class="tocitem" href="../../../common_workflows/hyperparameter_tuning/notebook/">Hyperparameter Tuning</a></li><li><a class="tocitem" href="../../../common_workflows/composition/notebook/">Model Composition</a></li><li><a class="tocitem" href="../../../common_workflows/comparison/notebook/">Model Comparison</a></li><li><a class="tocitem" href="../../../common_workflows/early_stopping/notebook/">Early Stopping</a></li><li><a class="tocitem" href="../../../common_workflows/live_training/notebook/">Live Training</a></li><li><a class="tocitem" href="../../../common_workflows/architecture_search/notebook/">Neural Architecture Search</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox" checked/><label class="tocitem" for="menuitem-4"><span class="docs-label">Extended Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../MNIST/notebook/">MNIST Images</a></li><li class="is-active"><a class="tocitem" href>Spam Detection with RNNs</a><ul class="internal"><li><a class="tocitem" href="#Train-the-Model"><span>Train the Model</span></a></li><li><a class="tocitem" href="#Evaluate-the-Model"><span>Evaluate the Model</span></a></li></ul></li></ul></li><li><a class="tocitem" href="../../../contributing/">Contributing</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Extended Examples</a></li><li class="is-active"><a href>Spam Detection with RNNs</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Spam Detection with RNNs</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/FluxML/MLJFlux.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/FluxML/MLJFlux.jl/blob/dev/docs/src/extended_examples/spam_detection/notebook.jl" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="SMS-Spam-Detection-with-RNNs"><a class="docs-heading-anchor" href="#SMS-Spam-Detection-with-RNNs">SMS Spam Detection with RNNs</a><a id="SMS-Spam-Detection-with-RNNs-1"></a><a class="docs-heading-anchor-permalink" href="#SMS-Spam-Detection-with-RNNs" title="Permalink"></a></h1><p>This demonstration is available as a Jupyter notebook or julia script <a href="https://github.com/FluxML/MLJFlux.jl/tree/dev/docs/src/extended_examples/spam_detection">here</a>.</p><p>In this demo we use a custom RNN model from Flux with MLJFlux to classify text messages as spam or ham. We will be using the <a href="https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset">SMS Collection Dataset</a> from Kaggle.</p><p><strong>Warning.</strong> This demo includes some non-idiomatic use of MLJ to allow use of the Flux.jl <code>Embedding</code> layer. It is not recommended for MLJ beginners.</p><h3 id="Basic-Imports"><a class="docs-heading-anchor" href="#Basic-Imports">Basic Imports</a><a id="Basic-Imports-1"></a><a class="docs-heading-anchor-permalink" href="#Basic-Imports" title="Permalink"></a></h3><pre><code class="language-julia hljs">using MLJ
using MLJFlux
using Flux
import Optimisers       # Flux.jl native optimisers no longer supported
using CSV               # Read data
using DataFrames        # Read data
using WordTokenizers    # For tokenization
using Languages         # For stop words</code></pre><h3 id="Reading-Data"><a class="docs-heading-anchor" href="#Reading-Data">Reading Data</a><a id="Reading-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Reading-Data" title="Permalink"></a></h3><p>We assume the <a href="https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset">SMS Collection Dataset</a> has been downloaded and is in a file called &quot;sms.csv&quot; in the same directory as the this script.</p><pre><code class="language-julia hljs">df = CSV.read(joinpath(@__DIR__, &quot;sms.csv&quot;), DataFrame);</code></pre><p>Display the first 5 rows with DataFrames</p><pre><code class="language-julia hljs">first(df, 5)</code></pre><div><div style = "float: left;"><span>5×2 DataFrame</span></div><div style = "clear: both;"></div></div><div class = "data-frame" style = "overflow-x: scroll;"><table class = "data-frame" style = "margin-bottom: 6px;"><thead><tr class = "header"><th class = "rowNumber" style = "font-weight: bold; text-align: right;">Row</th><th style = "text-align: left;">Category</th><th style = "text-align: left;">Message</th></tr><tr class = "subheader headerLastRow"><th class = "rowNumber" style = "font-weight: bold; text-align: right;"></th><th title = "InlineStrings.String7" style = "text-align: left;">String7</th><th title = "String" style = "text-align: left;">String</th></tr></thead><tbody><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">1</td><td style = "text-align: left;">ham</td><td style = "text-align: left;">Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">2</td><td style = "text-align: left;">ham</td><td style = "text-align: left;">Ok lar... Joking wif u oni...</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">3</td><td style = "text-align: left;">spam</td><td style = "text-align: left;">Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C&apos;s apply 08452810075over18&apos;s</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">4</td><td style = "text-align: left;">ham</td><td style = "text-align: left;">U dun say so early hor... U c already then say...</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">5</td><td style = "text-align: left;">ham</td><td style = "text-align: left;">Nah I don&apos;t think he goes to usf, he lives around here though</td></tr></tbody></table></div><h3 id="Text-Preprocessing"><a class="docs-heading-anchor" href="#Text-Preprocessing">Text Preprocessing</a><a id="Text-Preprocessing-1"></a><a class="docs-heading-anchor-permalink" href="#Text-Preprocessing" title="Permalink"></a></h3><p>Let&#39;s define a function that given an SMS message would:</p><ul><li><p>Tokenize it (i.e., convert it into a vector of words)</p></li><li><p>Remove stop words (i.e., words that are not useful for the analysis, like &quot;the&quot;, &quot;a&quot;, etc.)</p></li><li><p>Return the filtered vector of words</p></li></ul><pre><code class="language-julia hljs">const STOP_WORDS = Languages.stopwords(Languages.English())

function preprocess_text(text)
    # (1) Splitting texts into words (so later it can be a sequence of vectors)
    tokens = WordTokenizers.tokenize(text)

    # (2) Stop word removal
    filtered_tokens = filter(token -&gt; !(token in STOP_WORDS), tokens)

    return filtered_tokens
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">preprocess_text (generic function with 1 method)</code></pre><p>Define the vocabulary to be the set of all words in our training set. We also need a function that would map each word in a given sequence of words into its index in the dictionary (which is equivalent to representing the words as one-hot vectors).</p><p>Now after we do this the sequences will all be numerical vectors but they will be of unequal length. Thus, to facilitate batching of data for the deep learning model, we need to decide on a specific maximum length for all sequences and:</p><ul><li><p>If a sequence is longer than the maximum length, we need to truncate it</p></li><li><p>If a sequence is shorter than the maximum length, we need to pad it with a new token</p></li></ul><p>Lastly, we must also handle the case that an incoming text sequence may involve words never seen in training by represent all such out-of-vocabulary words with a new token.</p><p>We will define a function that would do this for us.</p><pre><code class="language-julia hljs">function encode_and_equalize(text_seq, vocab_dict, max_length, pad_val, oov_val)
    # (1) encode using the vocabulary
    text_seq_inds = [get(vocab_dict, word, oov_val) for word in text_seq]

    # (2) truncate sequence if &gt; max_length
    length(text_seq_inds) &gt; max_length &amp;&amp; (text_seq_inds = text_seq_inds[1:max_length])

    # (3) pad with pad_val
    text_seq_inds = vcat(text_seq_inds, fill(pad_val, max_length - length(text_seq_inds)))

    return text_seq_inds
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">encode_and_equalize (generic function with 1 method)</code></pre><h3 id="Preparing-Data"><a class="docs-heading-anchor" href="#Preparing-Data">Preparing Data</a><a id="Preparing-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Preparing-Data" title="Permalink"></a></h3><p>Splitting the data</p><pre><code class="language-julia hljs">x_data, y_data = unpack(df, ==(:Message), ==(:Category))
y_data = coerce(y_data, Multiclass);

(x_train, x_val), (y_train, y_val) = partition(
    (x_data, y_data),
    0.8,
    multi = true,
    shuffle = true,
    rng = 42,
);</code></pre><p>Now let&#39;s process the training and validation sets:</p><pre><code class="language-julia hljs">x_train_processed = [preprocess_text(text) for text in x_train]
x_val_processed = [preprocess_text(text) for text in x_val];</code></pre><p>sanity check</p><pre><code class="language-julia hljs">println(x_train_processed[1], &quot; is &quot;, y_data[1])</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">[&quot;Que&quot;, &quot;pases&quot;, &quot;un&quot;, &quot;buen&quot;, &quot;tiempo&quot;] is ham</code></pre><p>Define the vocabulary from the training data</p><pre><code class="language-julia hljs">vocab = unique(vcat(x_train_processed...))
vocab_dict = Dict(word =&gt; idx for (idx, word) in enumerate(vocab))
vocab_size = length(vocab)
pad_val, oov_val = vocab_size + 1, vocab_size + 2
max_length = 12                 # can choose this more smartly if you wish</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">12</code></pre><p>Encode and equalize training and validation data:</p><pre><code class="language-julia hljs">x_train_processed_equalized = [
    encode_and_equalize(seq, vocab_dict, max_length, pad_val, oov_val) for
        seq in x_train_processed
        ]
x_val_processed_equalized = [
    encode_and_equalize(seq, vocab_dict, max_length, pad_val, oov_val) for
        seq in x_val_processed
        ]
x_train_processed_equalized[1:5]        # all sequences are encoded and of the same length</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">5-element Vector{Vector{Int64}}:
 [1, 2, 3, 4, 5, 10404, 10404, 10404, 10404, 10404, 10404, 10404]
 [6, 7, 8, 9, 10, 11, 12, 13, 11, 14, 15, 16]
 [36, 37, 38, 39, 36, 40, 41, 42, 10404, 10404, 10404, 10404]
 [43, 24, 36, 44, 45, 46, 10404, 10404, 10404, 10404, 10404, 10404]
 [43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 44, 45]</code></pre><p>Convert both structures into matrix form:</p><pre><code class="language-julia hljs">matrixify(v) = reduce(hcat, v)&#39;
x_train_processed_equalized_fixed = matrixify(x_train_processed_equalized)
x_val_processed_equalized_fixed = matrixify(x_val_processed_equalized)
size(x_train_processed_equalized_fixed)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(4458, 12)</code></pre><h3 id="Instantiate-Model"><a class="docs-heading-anchor" href="#Instantiate-Model">Instantiate Model</a><a id="Instantiate-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Instantiate-Model" title="Permalink"></a></h3><p>For the model, we will use a RNN from Flux. We will average the hidden states corresponding to any sequence then pass that to a dense layer for classification.</p><p>For this, we need to define a custom Flux layer to perform the averaging operation:</p><pre><code class="language-julia hljs">struct Mean end
Flux.@layer Mean
(m::Mean)(x) = mean(x, dims = 2)[:, 1, :]   # [batch_size, seq_len, hidden_dim] =&gt; [batch_size, 1, hidden_dim]=&gt; [batch_size, hidden_dim]</code></pre><p>For compatibility, we will also define a layer that simply casts the input to integers as the embedding layer in Flux expects integers but the MLJFlux model expects floats:</p><pre><code class="language-julia hljs">struct Intify end
Flux.@layer Intify
(m::Intify)(x) = Int.(x)</code></pre><p>Here we define our network:</p><pre><code class="language-julia hljs">builder = MLJFlux.@builder begin
    Chain(
        Intify(),                         # Cast input to integer
        Embedding(vocab_size + 2 =&gt; 300), # Embedding layer
        RNN(300, 50, tanh),               # RNN layer
        Mean(),                           # Mean pooling layer
        Dense(50, 2),                     # Classification dense layer
    )
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">GenericBuilder(apply = #15)
</code></pre><p>Notice that we used an embedding layer with input dimensionality <code>vocab_size + 2</code> to take into account the padding and out-of-vocabulary tokens. Recall that the indices in our input correspond to one-hot-vectors and the embedding layer&#39;s purpose is to learn to map them into meaningful dense vectors (of dimensionality 300 here).</p><ol><li>Load and instantiate model</li></ol><pre><code class="language-julia hljs">NeuralNetworkClassifier = @load NeuralNetworkClassifier pkg = MLJFlux
clf = NeuralNetworkClassifier(
    builder = builder,
    optimiser = Optimisers.Adam(0.1),
    batch_size = 128,
    epochs = 10,
)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">NeuralNetworkClassifier(
  builder = GenericBuilder(
        apply = Main.var&quot;#15#16&quot;()), 
  finaliser = NNlib.softmax, 
  optimiser = Adam(0.1, (0.9, 0.999), 1.0e-8), 
  loss = Flux.Losses.crossentropy, 
  epochs = 10, 
  batch_size = 128, 
  lambda = 0.0, 
  alpha = 0.0, 
  rng = Random.TaskLocalRNG(), 
  optimiser_changes_trigger_retraining = false, 
  acceleration = CPU1{Nothing}(nothing), 
  embedding_dims = Dict{Symbol, Real}())</code></pre><ol><li>Wrap it in a machine</li></ol><pre><code class="language-julia hljs">x_train_processed_equalized_fixed = coerce(x_train_processed_equalized_fixed, Continuous)
mach = machine(clf, x_train_processed_equalized_fixed, y_train)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">untrained Machine; caches model-specific representations of data
  model: NeuralNetworkClassifier(builder = GenericBuilder(apply = #15), …)
  args: 
    1:	Source @863 ⏎ AbstractMatrix{ScientificTypesBase.Continuous}
    2:	Source @024 ⏎ AbstractVector{ScientificTypesBase.Multiclass{2}}
</code></pre><h2 id="Train-the-Model"><a class="docs-heading-anchor" href="#Train-the-Model">Train the Model</a><a id="Train-the-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Train-the-Model" title="Permalink"></a></h2><pre><code class="language- hljs">fit!(mach)</code></pre><h2 id="Evaluate-the-Model"><a class="docs-heading-anchor" href="#Evaluate-the-Model">Evaluate the Model</a><a id="Evaluate-the-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Evaluate-the-Model" title="Permalink"></a></h2><pre><code class="language- hljs">ŷ = predict_mode(mach, x_val_processed_equalized_fixed)
balanced_accuracy(ŷ, y_val)</code></pre><p>Acceptable performance. Let&#39;s see some live examples:</p><pre><code class="language- hljs">using Random: Random;
Random.seed!(99);

z = rand(x_val)
z_processed = preprocess_text(z)
z_encoded_equalized =
    encode_and_equalize(z_processed, vocab_dict, max_length, pad_val, oov_val)
z_encoded_equalized_fixed = matrixify([z_encoded_equalized])
z_encoded_equalized_fixed = coerce(z_encoded_equalized_fixed, Continuous)
z_pred = predict_mode(mach, z_encoded_equalized_fixed)

print(&quot;SMS: `$(z)` and the prediction is `$(z_pred)`&quot;)</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../MNIST/notebook/">« MNIST Images</a><a class="docs-footer-nextpage" href="../../../contributing/">Contributing »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.1 on <span class="colophon-date" title="Tuesday 11 February 2025 23:42">Tuesday 11 February 2025</span>. Using Julia version 1.10.8.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
