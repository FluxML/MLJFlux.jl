<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Introduction · MLJFlux</title><meta name="title" content="Introduction · MLJFlux"/><meta property="og:title" content="Introduction · MLJFlux"/><meta property="twitter:title" content="Introduction · MLJFlux"/><meta name="description" content="Documentation for MLJFlux."/><meta property="og:description" content="Documentation for MLJFlux."/><meta property="twitter:description" content="Documentation for MLJFlux."/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script><link href="assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,100;0,300;0,400;0,700;0,900;1,100;1,300;1,400;1,700;1,900&amp;family=Montserrat:ital,wght@0,100..900;1,100..900&amp;display=swap" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href><img src="assets/logo.gif" alt="MLJFlux logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href>MLJFlux</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Introduction</a><ul class="internal"><li><a class="tocitem" href="#Objectives"><span>Objectives</span></a></li><li><a class="tocitem" href="#Installation"><span>Installation</span></a></li><li><a class="tocitem" href="#Quick-Start"><span>Quick Start</span></a></li><li><a class="tocitem" href="#Basic-idea"><span>Basic idea</span></a></li><li><a class="tocitem" href="#Flux-or-MLJFlux?"><span>Flux or MLJFlux?</span></a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2" type="checkbox"/><label class="tocitem" for="menuitem-2"><span class="docs-label">Interface</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="interface/Summary/">Summary</a></li><li><a class="tocitem" href="interface/Builders/">Builders</a></li><li><a class="tocitem" href="interface/Custom Builders/">Custom Builders</a></li><li><a class="tocitem" href="interface/Classification/">Classification</a></li><li><a class="tocitem" href="interface/Regression/">Regression</a></li><li><a class="tocitem" href="interface/Multitarget Regression/">Multi-Target Regression</a></li><li><a class="tocitem" href="interface/Image Classification/">Image Classification</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">Workflow Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="workflow examples/Incremental Training/incremental/">Incremental Training</a></li><li><a class="tocitem" href="workflow examples/Hyperparameter Tuning/tuning/">Hyperparameter Tuning</a></li><li><a class="tocitem" href="workflow examples/Basic Neural Architecture Search/tuning/">Neural Architecture Search</a></li><li><a class="tocitem" href="workflow examples/Composition/composition/">Model Composition</a></li><li><a class="tocitem" href="workflow examples/Comparison/comparison/">Model Comparison</a></li><li><a class="tocitem" href="workflow examples/Early Stopping/iteration/">Early Stopping</a></li><li><a class="tocitem" href="workflow examples/Live Training/live-training/">Live Training</a></li></ul></li><li><a class="tocitem" href="contributing/">Contributing</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Introduction</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Introduction</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/FluxML/MLJFlux.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/FluxML/MLJFlux.jl/blob/dev/docs/src/index.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="MLJFlux.jl"><a class="docs-heading-anchor" href="#MLJFlux.jl">MLJFlux.jl</a><a id="MLJFlux.jl-1"></a><a class="docs-heading-anchor-permalink" href="#MLJFlux.jl" title="Permalink"></a></h1><p>A Julia package integrating deep learning Flux models with <a href="https://juliaai.github.io/MLJ.jl/dev/">MLJ</a>.</p><h2 id="Objectives"><a class="docs-heading-anchor" href="#Objectives">Objectives</a><a id="Objectives-1"></a><a class="docs-heading-anchor-permalink" href="#Objectives" title="Permalink"></a></h2><ul><li><p>Provide a user-friendly and high-level interface to fundamental <a href="https://fluxml.ai/Flux.jl/stable/">Flux</a> deep learning models while still being extensible by supporting custom models written with Flux</p></li><li><p>Make building deep learning models more convenient to users already familiar with the MLJ workflow</p></li><li><p>Make it easier to apply machine learning techniques provided by MLJ, including: out-of-sample performance evaluation, hyper-parameter optimization, iteration control, and more, to deep learning models</p></li></ul><div class="admonition is-info"><header class="admonition-header">MLJFlux Coverage</header><div class="admonition-body"><p>MLJFlux support is focused on fundamental and widely used deep learning models.  Sophisticated architectures or techniques such as online learning, reinforcement learning, and adversarial networks are currently beyond its scope. </p></div></div><p>Also note that MLJFlux is limited to training models only when all training data fits into memory, though it still supports automatic batching of data.</p><h2 id="Installation"><a class="docs-heading-anchor" href="#Installation">Installation</a><a id="Installation-1"></a><a class="docs-heading-anchor-permalink" href="#Installation" title="Permalink"></a></h2><pre><code class="language-julia hljs">import Pkg
Pkg.activate(&quot;my_environment&quot;, shared=true)
Pkg.add([&quot;MLJ&quot;, &quot;MLJFlux&quot;, &quot;Flux&quot;])</code></pre><p>You only need <code>Flux</code> if you need to build a custom architecture or experiment with different optimizers, loss functions and activations.</p><h2 id="Quick-Start"><a class="docs-heading-anchor" href="#Quick-Start">Quick Start</a><a id="Quick-Start-1"></a><a class="docs-heading-anchor-permalink" href="#Quick-Start" title="Permalink"></a></h2><pre><code class="language- hljs">using MLJ, Flux, MLJFlux
import RDatasets

# 1. Load Data
iris = RDatasets.dataset(&quot;datasets&quot;, &quot;iris&quot;);
y, X = unpack(iris, ==(:Species), colname -&gt; true, rng=123);

# 2. Load and instantiate model
NeuralNetworkClassifier = @load NeuralNetworkClassifier pkg=&quot;MLJFlux&quot;
clf = NeuralNetworkClassifier(
    builder=MLJFlux.MLP(; hidden=(5,4), σ=Flux.relu),
    optimiser=Flux.ADAM(0.01),
    batch_size=8,
    epochs=100, 
    acceleration=CUDALibs()         # For GPU support
    )

# 3. Wrap it in a machine 
mach = machine(clf, X, y)

# 4. Evaluate the model
cv=CV(nfolds=5)
evaluate!(mach, resampling=cv, measure=accuracy) </code></pre><p>As you can see we were able to use MLJ functionality (i.e., cross validation) with a Flux deep learning model. All arguments provided also have defaults.</p><p>Notice that we were also able to define the neural network in a high-level fashion by only specifying the number of neurons in each hidden layer and the activation function. Meanwhile, <code>MLJFlux</code> was able to infer the input and output layer as well as use a suitable default for the loss function and output activation given the classification task. Notice as well that we did not need to implement a training or prediction loop as in <code>Flux</code>.</p><h2 id="Basic-idea"><a class="docs-heading-anchor" href="#Basic-idea">Basic idea</a><a id="Basic-idea-1"></a><a class="docs-heading-anchor-permalink" href="#Basic-idea" title="Permalink"></a></h2><p>As in the example above, any MLJFlux model has a <code>builder</code> hyperparameter, an object encoding instructions for creating a neural network given the data that the model eventually sees (e.g., the number of classes in a classification problem). While each MLJ model has a simple default builder, users may need to define custom builders to get optimal results, and this will require familiarity with the <a href="https://fluxml.ai/Flux.jl/stable/">Flux API</a> for defining a neural network chain.</p><h2 id="Flux-or-MLJFlux?"><a class="docs-heading-anchor" href="#Flux-or-MLJFlux?">Flux or MLJFlux?</a><a id="Flux-or-MLJFlux?-1"></a><a class="docs-heading-anchor-permalink" href="#Flux-or-MLJFlux?" title="Permalink"></a></h2><p><a href="https://fluxml.ai/Flux.jl/stable/">Flux</a> is a deep learning framework in Julia that comes with everything you need to build deep learning models (i.e., GPU support, automatic differentiation, layers, activations, losses, optimizers, etc.). <a href="https://github.com/FluxML/MLJFlux.jl">MLJFlux</a> wraps models built with Flux which provides a more high-level interface for building and training such models. More importantly, it empowers Flux models by extending their support to many common machine learning workflows that are possible via MLJ such as:</p><ul><li><p><strong>Estimating performance</strong> of your model using a holdout set or other resampling strategy (e.g., cross-validation) as measured by one or more metrics (e.g., loss functions) that may not have been used in training</p></li><li><p><strong>Optimizing hyper-parameters</strong> such as a regularization parameter (e.g., dropout) or a width/height/nchannnels of convolution layer</p></li><li><p><strong>Compose with other models</strong> such as introducing data pre-processing steps (e.g., missing data imputation) into a pipeline. It might make sense to include non-deep learning models in this pipeline. Other kinds of model composition could include blending predictions of a deep learner with some other kind of model (as in “model stacking”). Models composed with MLJ can be also tuned as a single unit.</p></li><li><p><strong>Controlling iteration</strong> by adding an early stopping criterion based on an out-of-sample estimate of the loss, dynamically changing the learning rate (eg, cyclic learning rates), periodically save snapshots of the model, generate live plots of sample weights to judge training progress (as in tensor board)</p></li></ul><ul><li><strong>Comparing</strong> your model with a non-deep learning models</li></ul><p>A comparable project, <a href="https://github.com/FluxML/FastAI.jl">FastAI</a>/<a href="https://github.com/FluxML/FluxTraining.jl">FluxTraining</a>, also provides a high-level interface for interacting with Flux models and supports a set of features that may overlap with (but not include all of) those supported by MLJFlux.</p><p>Many of the features mentioned above are showcased in the workflow examples that you can access from the sidebar.</p></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="interface/Summary/">Summary »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.1 on <span class="colophon-date" title="Monday 10 June 2024 21:00">Monday 10 June 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
