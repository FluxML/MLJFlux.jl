<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Summary · MLJFlux</title><meta name="title" content="Summary · MLJFlux"/><meta property="og:title" content="Summary · MLJFlux"/><meta property="twitter:title" content="Summary · MLJFlux"/><meta name="description" content="Documentation for MLJFlux."/><meta property="og:description" content="Documentation for MLJFlux."/><meta property="twitter:description" content="Documentation for MLJFlux."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,100;0,300;0,400;0,700;0,900;1,100;1,300;1,400;1,700;1,900&amp;family=Montserrat:ital,wght@0,100..900;1,100..900&amp;display=swap" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.gif" alt="MLJFlux logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">MLJFlux</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Introduction</a></li><li><input class="collapse-toggle" id="menuitem-2" type="checkbox" checked/><label class="tocitem" for="menuitem-2"><span class="docs-label">Interface</span><i class="docs-chevron"></i></label><ul class="collapsed"><li class="is-active"><a class="tocitem" href>Summary</a><ul class="internal"><li><a class="tocitem" href="#Models"><span>Models</span></a></li><li><a class="tocitem" href="#Model-Hyperparameters."><span>Model Hyperparameters.</span></a></li><li><a class="tocitem" href="#Builders"><span>Builders</span></a></li></ul></li><li><a class="tocitem" href="../Builders/">Builders</a></li><li><a class="tocitem" href="../Custom Builders/">Custom Builders</a></li><li><a class="tocitem" href="../Classification/">Classification</a></li><li><a class="tocitem" href="../Regression/">Regression</a></li><li><a class="tocitem" href="../Multitarget Regression/">Multi-Target Regression</a></li><li><a class="tocitem" href="../Image Classification/">Image Classification</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">Common Workflows</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../common_workflows/incremental_training/notebook/">Incremental Training</a></li><li><a class="tocitem" href="../../common_workflows/hyperparameter_tuning/notebook/">Hyperparameter Tuning</a></li><li><a class="tocitem" href="../../common_workflows/composition/notebook/">Model Composition</a></li><li><a class="tocitem" href="../../common_workflows/comparison/notebook/">Model Comparison</a></li><li><a class="tocitem" href="../../common_workflows/early_stopping/notebook/">Early Stopping</a></li><li><a class="tocitem" href="../../common_workflows/live_training/notebook/">Live Training</a></li><li><a class="tocitem" href="../../common_workflows/architecture_search/notebook/">Neural Architecture Search</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">Extended Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../extended_examples/MNIST/notebook/">MNIST Images</a></li><li><a class="tocitem" href="../../extended_examples/spam_detection/notebook/">Spam Detection with RNNs</a></li></ul></li><li><a class="tocitem" href="../../contributing/">Contributing</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Interface</a></li><li class="is-active"><a href>Summary</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Summary</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/FluxML/MLJFlux.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/FluxML/MLJFlux.jl/blob/dev/docs/src/interface/Summary.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h2 id="Models"><a class="docs-heading-anchor" href="#Models">Models</a><a id="Models-1"></a><a class="docs-heading-anchor-permalink" href="#Models" title="Permalink"></a></h2><p>MLJFlux provides the model types below, for use with input features <code>X</code> and targets <code>y</code> of the <a href="https://juliaai.github.io/ScientificTypes.jl/dev/">scientific type</a> indicated in the table below. The parameters <code>n_in</code>, <code>n_out</code> and <code>n_channels</code> refer to information passed to the builder, as described under <a href="../Custom Builders/#Defining-Custom-Builders">Defining Custom Builders</a>.</p><table><tr><th style="text-align: right">Model Type</th><th style="text-align: right">Prediction type</th><th style="text-align: right"><code>scitype(X) &lt;: _</code></th><th style="text-align: right"><code>scitype(y) &lt;: _</code></th></tr><tr><td style="text-align: right"><a href="../Regression/#MLJFlux.NeuralNetworkRegressor"><code>NeuralNetworkRegressor</code></a></td><td style="text-align: right"><code>Deterministic</code></td><td style="text-align: right"><code>AbstractMatrix{Continuous}</code> or <code>Table(Continuous)</code> with <code>n_in</code> columns</td><td style="text-align: right"><code>AbstractVector{&lt;:Continuous)</code> (<code>n_out = 1</code>)</td></tr><tr><td style="text-align: right"><a href="../Multitarget Regression/#MLJFlux.MultitargetNeuralNetworkRegressor"><code>MultitargetNeuralNetworkRegressor</code></a></td><td style="text-align: right"><code>Deterministic</code></td><td style="text-align: right"><code>AbstractMatrix{Continuous}</code> or <code>Table(Continuous)</code> with <code>n_in</code> columns</td><td style="text-align: right"><code>&lt;: Table(Continuous)</code> with <code>n_out</code> columns</td></tr><tr><td style="text-align: right"><a href="../Classification/#MLJFlux.NeuralNetworkClassifier"><code>NeuralNetworkClassifier</code></a></td><td style="text-align: right"><code>Probabilistic</code></td><td style="text-align: right"><code>AbstractMatrix{Continuous}</code> or <code>Table(Continuous)</code> with <code>n_in</code> columns</td><td style="text-align: right"><code>AbstractVector{&lt;:Finite}</code> with <code>n_out</code> classes</td></tr><tr><td style="text-align: right"><a href="../Classification/#MLJFlux.NeuralNetworkBinaryClassifier"><code>NeuralNetworkBinaryClassifier</code></a></td><td style="text-align: right"><code>Probabilistic</code></td><td style="text-align: right"><code>AbstractMatrix{Continuous}</code> or <code>Table(Continuous)</code> with <code>n_in</code> columns</td><td style="text-align: right"><code>AbstractVector{&lt;:Finite{2}}</code> (but <code>n_out = 1</code>)</td></tr><tr><td style="text-align: right"><a href="../Image Classification/#MLJFlux.ImageClassifier"><code>ImageClassifier</code></a></td><td style="text-align: right"><code>Probabilistic</code></td><td style="text-align: right"><code>AbstractVector(&lt;:Image{W,H})</code> with <code>n_in = (W, H)</code></td><td style="text-align: right"><code>AbstractVector{&lt;:Finite}</code> with <code>n_out</code> classes</td></tr></table><details><summary><b>What exactly is a "model"?</b></summary><p>In MLJ a <em>model</em> is a mutable struct storing hyper-parameters for some learning algorithm indicated by the model name, and that&#39;s all. In particular, an MLJ model does not store learned parameters.</p><div class="admonition is-warning"><header class="admonition-header">Difference in Definition</header><div class="admonition-body"><p>In Flux the term &quot;model&quot; has another meaning. However, as all Flux &quot;models&quot; used in MLJFLux are <code>Flux.Chain</code> objects, we call them <em>chains</em>, and restrict use of &quot;model&quot; to models in the MLJ sense.</p></div></div></details><details open><summary><b>Are oberservations rows or columns?</b></summary><p>In MLJ the convention for two-dimensional data (tables and matrices) is <strong>rows=obervations</strong>. For matrices Flux has the opposite convention. If your data is a matrix with whose column index the observation index, then your optimal solution is to present the <code>adjoint</code> or <code>transpose</code> of your matrix to MLJFlux models. Otherwise, you can use the matrix as is, or transform one time with <code>permutedims</code>, and again present the <code>adjoint</code> or <code>transpose</code> as the optimal solution for MLJFlux training.</p></details><p>Instructions for coercing common image formats into some <code>AbstractVector{&lt;:Image}</code> are <a href="https://juliaai.github.io/ScientificTypes.jl/dev/#Type-coercion-for-image-data">here</a>.</p><details closed><summary><b>Fitting and warm restarts</b></summary><p>MLJ machines cache state enabling the &quot;warm restart&quot; of model training, as demonstrated in the incremental training example. In the case of MLJFlux models, <code>fit!(mach)</code> will use a warm restart if:</p><ul><li><p>only <code>model.epochs</code> has changed since the last call; or</p></li><li><p>only <code>model.epochs</code> or <code>model.optimiser</code> have changed since the last call and <code>model.optimiser_changes_trigger_retraining == false</code> (the default) (the &quot;state&quot; part of the optimiser is ignored in this comparison). This allows one to dynamically modify learning rates, for example.</p></li></ul><p>Here <code>model=mach.model</code> is the associated MLJ model.</p><p>The warm restart feature makes it possible to externally control iteration. See, for example, <a href="@ref">Early Stopping with MLJFlux</a> and <a href="../../extended_examples/MNIST/notebook/#Using-MLJ-to-classifiy-the-MNIST-image-dataset">Using MLJ to classifiy the MNIST image dataset</a>.</p></details><h2 id="Model-Hyperparameters."><a class="docs-heading-anchor" href="#Model-Hyperparameters.">Model Hyperparameters.</a><a id="Model-Hyperparameters.-1"></a><a class="docs-heading-anchor-permalink" href="#Model-Hyperparameters." title="Permalink"></a></h2><p>All models share the following hyper-parameters. See individual model docstrings for a full list.</p><table><tr><th style="text-align: right">Hyper-parameter</th><th style="text-align: right">Description</th><th style="text-align: right">Default</th></tr><tr><td style="text-align: right"><code>builder</code></td><td style="text-align: right">Default builder for models.</td><td style="text-align: right"><code>MLJFlux.Linear(σ=Flux.relu)</code> (regressors) or <code>MLJFlux.Short(n_hidden=0, dropout=0.5, σ=Flux.σ)</code> (classifiers)</td></tr><tr><td style="text-align: right"><code>optimiser</code></td><td style="text-align: right">The optimiser to use for training.</td><td style="text-align: right"><code>Optimiser.Adam()</code></td></tr><tr><td style="text-align: right"><code>loss</code></td><td style="text-align: right">The loss function used for training.</td><td style="text-align: right"><code>Flux.mse</code> (regressors) and <code>Flux.crossentropy</code> (classifiers)</td></tr><tr><td style="text-align: right"><code>n_epochs</code></td><td style="text-align: right">Number of epochs to train for.</td><td style="text-align: right"><code>10</code></td></tr><tr><td style="text-align: right"><code>batch_size</code></td><td style="text-align: right">The batch size for the data.</td><td style="text-align: right"><code>1</code></td></tr><tr><td style="text-align: right"><code>lambda</code></td><td style="text-align: right">The regularization strength. Range = [0, ∞).</td><td style="text-align: right"><code>0</code></td></tr><tr><td style="text-align: right"><code>alpha</code></td><td style="text-align: right">The L2/L1 mix of regularization. Range = [0, 1].</td><td style="text-align: right"><code>0</code></td></tr><tr><td style="text-align: right"><code>rng</code></td><td style="text-align: right">The random number generator (RNG) passed to builders, for weight initialization, for example. Can be any <code>AbstractRNG</code> or the seed (integer) for a <code>Xoshirio</code> that is reset on every cold restart of model (machine) training.</td><td style="text-align: right"><code>GLOBAL_RNG</code></td></tr><tr><td style="text-align: right"><code>acceleration</code></td><td style="text-align: right">Use <code>CUDALibs()</code> for training on GPU; default is <code>CPU1()</code>.</td><td style="text-align: right"><code>CPU1()</code></td></tr><tr><td style="text-align: right"><code>optimiser_changes_trigger_retraining</code></td><td style="text-align: right">True if fitting an associated machine should trigger retraining from scratch whenever the optimiser changes.</td><td style="text-align: right"><code>false</code></td></tr></table><p>The classifiers have an additional hyperparameter <code>finaliser</code> (default is <code>Flux.softmax</code>, or <code>Flux.σ</code> in the binary case) which is the operation applied to the unnormalized output of the final layer to obtain probabilities (outputs summing to one). It should return a vector of the same length as its input.</p><div class="admonition is-info"><header class="admonition-header">Loss Functions</header><div class="admonition-body"><p>Currently, the loss function specified by <code>loss=...</code> is applied internally by Flux and needs to conform to the Flux API. You cannot, for example, supply one of MLJ&#39;s probabilistic loss functions, such as <code>MLJ.cross_entropy</code> to one of the classifier constructors.</p></div></div><p>That said, you can only use MLJ loss functions or metrics in evaluation meta-algorithms (such as cross validation) and they will work even if the underlying model comes from <code>MLJFlux</code>.</p><details closed><summary><b>More on accelerated training with GPUs</b></summary><p>As in the table, when instantiating a model for training on a GPU, specify <code>acceleration=CUDALibs()</code>, as in</p><pre><code class="language-julia hljs">using MLJ
ImageClassifier = @load ImageClassifier
model = ImageClassifier(epochs=10, acceleration=CUDALibs())
mach = machine(model, X, y) |&gt; fit!</code></pre><p>In this example, the data <code>X, y</code> is copied onto the GPU under the hood on the call to <code>fit!</code> and cached for use in any warm restart (see above). The Flux chain used in training is always copied back to the CPU at then conclusion of <code>fit!</code>, and made available as <code>fitted_params(mach)</code>.</p></details><h2 id="Builders"><a class="docs-heading-anchor" href="#Builders">Builders</a><a id="Builders-1"></a><a class="docs-heading-anchor-permalink" href="#Builders" title="Permalink"></a></h2><table><tr><th style="text-align: left">Builder</th><th style="text-align: left">Description</th></tr><tr><td style="text-align: left"><a href="../Builders/#MLJFlux.MLP"><code>MLJFlux.MLP</code></a><code>(hidden=(10,))</code></td><td style="text-align: left">General multi-layer perceptron</td></tr><tr><td style="text-align: left"><a href="../Builders/#MLJFlux.Short"><code>MLJFlux.Short</code></a><code>(n_hidden=0, dropout=0.5, σ=sigmoid)</code></td><td style="text-align: left">Fully connected network with one hidden layer and dropout</td></tr><tr><td style="text-align: left"><a href="../Builders/#MLJFlux.Linear"><code>MLJFlux.Linear</code></a><code>(σ=relu)</code></td><td style="text-align: left">Vanilla linear network with no hidden layers and activation function <code>σ</code></td></tr><tr><td style="text-align: left"><a href="../Builders/#MLJFlux.@builder"><code>MLJFlux.@builder</code></a></td><td style="text-align: left">Macro for customized builders</td></tr><tr><td style="text-align: left"></td><td style="text-align: left"></td></tr></table></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../">« Introduction</a><a class="docs-footer-nextpage" href="../Builders/">Builders »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Wednesday 13 November 2024 20:06">Wednesday 13 November 2024</span>. Using Julia version 1.10.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
