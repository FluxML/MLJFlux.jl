{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Model Comparison with MLJFlux"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This demonstration is available as a Jupyter notebook or julia script\n",
    "[here](https://github.com/FluxML/MLJFlux.jl/tree/dev/docs/src/common_workflows/comparison)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this workflow example, we see how we can compare different machine learning models\n",
    "with a neural network from MLJFlux."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Activating project at `~/GoogleDrive/Julia/MLJ/MLJFlux/docs`\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "using Pkg\n",
    "PKG_ENV = joinpath(@__DIR__, \"..\", \"..\", \"..\")\n",
    "Pkg.activate(PKG_ENV);\n",
    "Pkg.instantiate();"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "**This script tested using Julia 1.10**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Basic Imports"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "stable_rng (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "cell_type": "code",
   "source": [
    "using MLJ               # Has MLJFlux models\n",
    "using Flux              # For more flexibility\n",
    "using DataFrames        # To visualize hyperparameter search results\n",
    "import Optimisers       # native Flux.jl optimisers no longer supported\n",
    "using Measurements       # to get ± functionality\n",
    "import CategoricalArrays.unwrap\n",
    "using StableRNGs        # for reproducibility across Julia versions\n",
    "\n",
    "stable_rng() = StableRNG(123)"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading and Splitting the Data"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(CategoricalArrays.CategoricalValue{String, UInt32}[\"versicolor\", \"virginica\", \"virginica\", \"setosa\", \"virginica\", \"virginica\", \"versicolor\", \"setosa\", \"virginica\", \"versicolor\"  …  \"setosa\", \"virginica\", \"virginica\", \"setosa\", \"versicolor\", \"setosa\", \"virginica\", \"versicolor\", \"versicolor\", \"setosa\"], (sepal_length = [6.1, 7.3, 6.3, 4.8, 5.9, 7.1, 6.7, 5.4, 6.0, 6.9  …  5.0, 6.4, 5.7, 4.6, 5.5, 4.6, 5.6, 5.7, 6.0, 5.0], sepal_width = [2.9, 2.9, 3.4, 3.4, 3.0, 3.0, 3.0, 3.9, 3.0, 3.1  …  3.3, 2.7, 2.5, 3.2, 2.4, 3.1, 2.8, 3.0, 2.9, 3.5], petal_length = [4.7, 6.3, 5.6, 1.9, 5.1, 5.9, 5.0, 1.7, 4.8, 4.9  …  1.4, 5.3, 5.0, 1.4, 3.7, 1.5, 4.9, 4.2, 4.5, 1.6], petal_width = [1.4, 1.8, 2.4, 0.2, 1.8, 2.1, 1.7, 0.4, 1.8, 1.5  …  0.2, 1.9, 2.0, 0.2, 1.0, 0.2, 2.0, 1.2, 1.5, 0.6]))"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "cell_type": "code",
   "source": [
    "iris = load_iris() # a named-tuple of vectors\n",
    "y, X = unpack(iris, ==(:target), rng=stable_rng())"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instantiating the models Now let's construct our model. This follows a similar setup\n",
    "to the one followed in the [Quick Start](../../index.md#Quick-Start)."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Info: For silent loading, specify `verbosity=0`. \n",
      "import MLJFlux ✔\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "NeuralNetworkClassifier(\n  builder = MLP(\n        hidden = (5, 4), \n        σ = NNlib.relu), \n  finaliser = NNlib.softmax, \n  optimiser = Optimisers.Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), \n  loss = Flux.Losses.crossentropy, \n  epochs = 50, \n  batch_size = 8, \n  lambda = 0.0, \n  alpha = 0.0, \n  rng = StableRNGs.LehmerRNG(state=0x000000000000000000000000000000f7), \n  optimiser_changes_trigger_retraining = false, \n  acceleration = ComputationalResources.CPU1{Nothing}(nothing), \n  embedding_dims = Dict{Symbol, Real}())"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "NeuralNetworkClassifier = @load NeuralNetworkClassifier pkg=MLJFlux\n",
    "\n",
    "clf1 = NeuralNetworkClassifier(\n",
    "    builder=MLJFlux.MLP(; hidden=(5,4), σ=Flux.relu),\n",
    "    optimiser=Optimisers.Adam(0.01),\n",
    "    batch_size=8,\n",
    "    epochs=50,\n",
    "    rng=stable_rng(),\n",
    "    )"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's as well load and construct three other classical machine learning models:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Info: For silent loading, specify `verbosity=0`. \n",
      "import MLJMultivariateStatsInterface ✔\n",
      "[ Info: For silent loading, specify `verbosity=0`. \n",
      "import MLJDecisionTreeInterface ✔\n",
      "[ Info: For silent loading, specify `verbosity=0`. \n",
      "import MLJXGBoostInterface ✔\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "BayesianLDA = @load BayesianLDA pkg=MultivariateStats\n",
    "clf2 = BayesianLDA()\n",
    "RandomForestClassifier = @load RandomForestClassifier pkg=DecisionTree\n",
    "clf3 = RandomForestClassifier()\n",
    "XGBoostClassifier = @load XGBoostClassifier pkg=XGBoost\n",
    "clf4 = XGBoostClassifier();"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wrapping One of the Models in a TunedModel"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instead of just comparing with four models with the default/given hyperparameters, we\n",
    "will give `XGBoostClassifier` an unfair advantage By wrapping it in a `TunedModel` that\n",
    "considers the best learning rate η for the model."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r1 = range(clf4, :eta, lower=0.01, upper=0.5, scale=:log10)\n",
    "tuned_model_xg = TunedModel(\n",
    "    model=clf4,\n",
    "    ranges=[r1],\n",
    "    tuning=Grid(resolution=10),\n",
    "    resampling=CV(nfolds=5, rng=stable_rng()),\n",
    "    measure=cross_entropy,\n",
    ");"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "Of course, one can wrap each of the four in a TunedModel if they are interested in\n",
    "comparing the models over a large set of their hyperparameters."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comparing the models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We simply pass the four models to the `models` argument of the `TunedModel` construct"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "tuned_model = TunedModel(\n",
    "    models=[clf1, clf2, clf3, tuned_model_xg],\n",
    "    tuning=Explicit(),\n",
    "    resampling=CV(nfolds=2, rng=stable_rng()),\n",
    "    repeats=5,\n",
    "    measure=cross_entropy,\n",
    ");"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice here we are using 5 x 2 Monte Carlo cross-validation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then wrapping our tuned model in a machine and fitting it."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "mach = machine(tuned_model, X, y);\n",
    "fit!(mach, verbosity=0);"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's see the history for more details on the performance for each of the models"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[1m4×2 DataFrame\u001b[0m\n\u001b[1m Row \u001b[0m│\u001b[1m mlp                               \u001b[0m\u001b[1m measurement \u001b[0m\n\u001b[1m     \u001b[0m│\u001b[90m Probabil…                         \u001b[0m\u001b[90m Measuremen… \u001b[0m\n─────┼────────────────────────────────────────────────\n   1 │ BayesianLDA(method = gevd, …)      0.059±0.015\n   2 │ RandomForestClassifier(max_depth…  0.116±0.017\n   3 │ NeuralNetworkClassifier(builder …  0.119±0.047\n   4 │ ProbabilisticTunedModel(model = …  0.29±0.12",
      "text/html": [
       "<div><div style = \"float: left;\"><span>4×2 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"columnLabelRow\"><th class = \"stubheadLabel\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">mlp</th><th style = \"text-align: left;\">measurement</th></tr><tr class = \"columnLabelRow\"><th class = \"stubheadLabel\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"MLJModelInterface.Probabilistic\" style = \"text-align: left;\">Probabil…</th><th title = \"Measurements.Measurement{Float64}\" style = \"text-align: left;\">Measurem…</th></tr></thead><tbody><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">BayesianLDA(method = gevd, …)</td><td style = \"text-align: right;\">0.059±0.015</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">RandomForestClassifier(max_depth = -1, …)</td><td style = \"text-align: right;\">0.116±0.017</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">NeuralNetworkClassifier(builder = MLP(hidden = (5, 4), …), …)</td><td style = \"text-align: right;\">0.119±0.047</td></tr><tr class = \"dataRow\"><td class = \"rowLabel\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">ProbabilisticTunedModel(model = XGBoostClassifier(test = 1, …), …)</td><td style = \"text-align: right;\">0.29±0.12</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "cell_type": "code",
   "source": [
    "history = report(mach).history\n",
    "history_df = DataFrame(\n",
    "    mlp = [x.model for x in history],\n",
    "    measurement = [\n",
    "        x.evaluation.measurement[1] ±\n",
    "            x.evaluation.uncertainty_radius_95[1] for x in history\n",
    "                ],\n",
    ")\n",
    "sort!(history_df, [order(:measurement)])"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is Occam's razor in practice."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.10"
  },
  "kernelspec": {
   "name": "julia-1.10",
   "display_name": "Julia 1.10.10",
   "language": "julia"
  }
 },
 "nbformat": 4
}
