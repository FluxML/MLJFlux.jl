{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Model Composition with MLJFlux"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This tutorial is available as a Jupyter notebook or julia script\n",
    "[here](https://github.com/FluxML/MLJFlux.jl/tree/dev/docs/src/common_workflows/composition)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this workflow example, we see how MLJFlux enables composing MLJ models with MLJFlux\n",
    "models. We will assume a class imbalance setting and wrap an oversampler with a deep\n",
    "learning model from MLJFlux."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Activating project at `~/GoogleDrive/Julia/MLJ/MLJFlux/docs/src/common_workflows/composition`\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "using Pkg\n",
    "Pkg.activate(@__DIR__);\n",
    "Pkg.instantiate();"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Julia version** is assumed to be 1.10.*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Basic Imports"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using MLJ               # Has MLJFlux models\n",
    "using Flux              # For more flexibility\n",
    "import RDatasets        # Dataset source\n",
    "import Random           # To create imbalance\n",
    "import Imbalance        # To solve the imbalance\n",
    "import Optimisers       # native Flux.jl optimisers no longer supported"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading and Splitting the Data"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "iris = RDatasets.dataset(\"datasets\", \"iris\");\n",
    "y, X = unpack(iris, ==(:Species), colname -> true, rng=123);\n",
    "X = Float32.(X);      # To be compatible with type of network network parameters"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "To simulate an imbalanced dataset, we will take a random sample:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versicolor: ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 28 (65.1%) \n",
      "virginica:  ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 29 (67.4%) \n",
      "setosa:     ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 43 (100.0%) \n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "Random.seed!(803429)\n",
    "subset_indices = rand(1:size(X, 1), 100)\n",
    "X, y = X[subset_indices, :], y[subset_indices]\n",
    "Imbalance.checkbalance(y)"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instantiating the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's load `BorderlineSMOTE1` to oversample the data and `Standardizer` to standardize\n",
    "it."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Info: For silent loading, specify `verbosity=0`. \n",
      "import MLJFlux ✔\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MLJFlux.NeuralNetworkClassifier"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "BorderlineSMOTE1 = @load BorderlineSMOTE1 pkg=Imbalance verbosity=0\n",
    "NeuralNetworkClassifier = @load NeuralNetworkClassifier pkg=MLJFlux"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "We didn't need to load Standardizer because it is a local model for MLJ (see\n",
    "`localmodels()`)"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "NeuralNetworkClassifier(\n  builder = MLP(\n        hidden = (5, 4), \n        σ = NNlib.relu), \n  finaliser = NNlib.softmax, \n  optimiser = Adam(0.01, (0.9, 0.999), 1.0e-8), \n  loss = Flux.Losses.crossentropy, \n  epochs = 50, \n  batch_size = 8, \n  lambda = 0.0, \n  alpha = 0.0, \n  rng = 42, \n  optimiser_changes_trigger_retraining = false, \n  acceleration = ComputationalResources.CPU1{Nothing}(nothing))"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "cell_type": "code",
   "source": [
    "clf = NeuralNetworkClassifier(\n",
    "    builder=MLJFlux.MLP(; hidden=(5,4), σ=Flux.relu),\n",
    "    optimiser=Optimisers.Adam(0.01),\n",
    "    batch_size=8,\n",
    "    epochs=50,\n",
    "    rng=42,\n",
    ")"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we wrap the oversampler with the neural network via the `BalancedModel`\n",
    "construct. This comes from `MLJBalancing` And allows combining resampling methods with\n",
    "MLJ models in a sequential pipeline."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Standardizer(\n  features = Symbol[], \n  ignore = false, \n  ordered_factor = false, \n  count = false)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "cell_type": "code",
   "source": [
    "oversampler = BorderlineSMOTE1(k=5, ratios=1.0, rng=42)\n",
    "balanced_model = BalancedModel(model=clf, balancer1=oversampler)\n",
    "standarizer = Standardizer()"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's compose the balanced model with a standardizer."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "ProbabilisticPipeline(\n  standardizer = Standardizer(\n        features = Symbol[], \n        ignore = false, \n        ordered_factor = false, \n        count = false), \n  balanced_model_probabilistic = BalancedModelProbabilistic(\n        model = NeuralNetworkClassifier(builder = MLP(hidden = (5, 4), …), …), \n        balancer1 = BorderlineSMOTE1(m = 5, …)), \n  cache = true)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "cell_type": "code",
   "source": [
    "pipeline = standarizer |> balanced_model"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "By this, any training data will be standardized then oversampled then passed to the\n",
    "model. Meanwhile, for inference, the standardizer will automatically use the training\n",
    "set's mean and std and the oversampler will be transparent."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training the Composed Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's indistinguishable from training a single model."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "[ Info: Training machine(:standardizer, …).\n",
      "[ Info: Training machine(:balanced_model_probabilistic, …).\n",
      "[ Info: Training machine(BorderlineSMOTE1(m = 5, …), …).\n",
      "[ Info: Training machine(:model, …).\n",
      "[ Info: After filtering, the mapping from each class to number of borderline points is (\"virginica\" => 1, \"versicolor\" => 2).\n",
      "\rProgress:  13%|███████▏                                             |  ETA: 0:00:01\u001b[K\rProgress: 100%|█████████████████████████████████████████████████████| Time: 0:00:00\u001b[K\n",
      "\rProgress:  67%|███████████████████████████████████▍                 |  ETA: 0:00:01\u001b[K\r\n",
      "  class:  virginica\u001b[K\r\u001b[A[ Info: After filtering, the mapping from each class to number of borderline points is (\"virginica\" => 1, \"versicolor\" => 2).\n",
      "\rOptimising neural net:   4%[>                        ]  ETA: 0:05:10\u001b[K\rOptimising neural net:   6%[=>                       ]  ETA: 0:03:22\u001b[K\rOptimising neural net:   8%[=>                       ]  ETA: 0:02:29\u001b[K\rOptimising neural net:  10%[==>                      ]  ETA: 0:01:56\u001b[K\rOptimising neural net:  12%[==>                      ]  ETA: 0:01:35\u001b[K\rOptimising neural net:  14%[===>                     ]  ETA: 0:01:20\u001b[K\rOptimising neural net:  16%[===>                     ]  ETA: 0:01:08\u001b[K\rOptimising neural net:  18%[====>                    ]  ETA: 0:00:59\u001b[K\rOptimising neural net:  20%[====>                    ]  ETA: 0:00:52\u001b[K\rOptimising neural net:  22%[=====>                   ]  ETA: 0:00:46\u001b[K\rOptimising neural net:  24%[=====>                   ]  ETA: 0:00:41\u001b[K\rOptimising neural net:  25%[======>                  ]  ETA: 0:00:37\u001b[K\rOptimising neural net:  27%[======>                  ]  ETA: 0:00:33\u001b[K\rOptimising neural net:  29%[=======>                 ]  ETA: 0:00:30\u001b[K\rOptimising neural net:  31%[=======>                 ]  ETA: 0:00:28\u001b[K\rOptimising neural net:  33%[========>                ]  ETA: 0:00:25\u001b[K\rOptimising neural net:  35%[========>                ]  ETA: 0:00:23\u001b[K\rOptimising neural net:  37%[=========>               ]  ETA: 0:00:21\u001b[K\rOptimising neural net:  39%[=========>               ]  ETA: 0:00:20\u001b[K\rOptimising neural net:  41%[==========>              ]  ETA: 0:00:18\u001b[K\rOptimising neural net:  43%[==========>              ]  ETA: 0:00:17\u001b[K\rOptimising neural net:  45%[===========>             ]  ETA: 0:00:15\u001b[K\rOptimising neural net:  47%[===========>             ]  ETA: 0:00:14\u001b[K\rOptimising neural net:  49%[============>            ]  ETA: 0:00:13\u001b[K\rOptimising neural net:  51%[============>            ]  ETA: 0:00:12\u001b[K\rOptimising neural net:  53%[=============>           ]  ETA: 0:00:11\u001b[K\rOptimising neural net:  55%[=============>           ]  ETA: 0:00:10\u001b[K\rOptimising neural net:  57%[==============>          ]  ETA: 0:00:10\u001b[K\rOptimising neural net:  59%[==============>          ]  ETA: 0:00:09\u001b[K\rOptimising neural net:  61%[===============>         ]  ETA: 0:00:08\u001b[K\rOptimising neural net:  63%[===============>         ]  ETA: 0:00:08\u001b[K\rOptimising neural net:  82%[====================>    ]  ETA: 0:00:03\u001b[K\rOptimising neural net:  84%[=====================>   ]  ETA: 0:00:02\u001b[K\rOptimising neural net:  86%[=====================>   ]  ETA: 0:00:02\u001b[K\rOptimising neural net:  88%[======================>  ]  ETA: 0:00:02\u001b[K\rOptimising neural net:  90%[======================>  ]  ETA: 0:00:01\u001b[K\rOptimising neural net:  92%[=======================> ]  ETA: 0:00:01\u001b[K\rOptimising neural net:  94%[=======================> ]  ETA: 0:00:01\u001b[K\rOptimising neural net:  96%[========================>]  ETA: 0:00:01\u001b[K\rOptimising neural net:  98%[========================>]  ETA: 0:00:00\u001b[K\rOptimising neural net: 100%[=========================] Time: 0:00:12\u001b[K\n",
      "[ Info: After filtering, the mapping from each class to number of borderline points is (\"virginica\" => 3, \"versicolor\" => 1).\n",
      "[ Info: After filtering, the mapping from each class to number of borderline points is (\"virginica\" => 3, \"versicolor\" => 1).\n",
      "[ Info: After filtering, the mapping from each class to number of borderline points is (\"versicolor\" => 2).\n",
      "┌ Warning: Cannot oversample a class with no borderline points. Skipping.\n",
      "└ @ Imbalance ~/.julia/packages/Imbalance/knJL1/src/oversampling_methods/borderline_smote1/borderline_smote1.jl:67\n",
      "[ Info: After filtering, the mapping from each class to number of borderline points is (\"versicolor\" => 2).\n",
      "┌ Warning: Cannot oversample a class with no borderline points. Skipping.\n",
      "└ @ Imbalance ~/.julia/packages/Imbalance/knJL1/src/oversampling_methods/borderline_smote1/borderline_smote1.jl:67\n",
      "┌ Warning: Layer with Float32 parameters got Float64 input.\n",
      "│   The input will be converted, but any earlier layers may be very slow.\n",
      "│   layer = Dense(4 => 5, relu)  # 25 parameters\n",
      "│   summary(x) = \"4×8 Matrix{Float64}\"\n",
      "└ @ Flux ~/.julia/packages/Flux/Wz6D4/src/layers/stateless.jl:60\n",
      "\rEvaluating over 5 folds:  40%[==========>              ]  ETA: 0:00:16\u001b[K[ Info: After filtering, the mapping from each class to number of borderline points is (\"virginica\" => 1, \"versicolor\" => 2).\n",
      "[ Info: After filtering, the mapping from each class to number of borderline points is (\"virginica\" => 1, \"versicolor\" => 2).\n",
      "\rEvaluating over 5 folds:  60%[===============>         ]  ETA: 0:00:07\u001b[K[ Info: After filtering, the mapping from each class to number of borderline points is (\"virginica\" => 1).\n",
      "┌ Warning: Cannot oversample a class with no borderline points. Skipping.\n",
      "└ @ Imbalance ~/.julia/packages/Imbalance/knJL1/src/oversampling_methods/borderline_smote1/borderline_smote1.jl:67\n",
      "\rProgress:  67%|███████████████████████████████████▍                 |  ETA: 0:00:00\u001b[K\r\n",
      "  class:  virginica\u001b[K\r\u001b[A[ Info: After filtering, the mapping from each class to number of borderline points is (\"virginica\" => 1).\n",
      "┌ Warning: Cannot oversample a class with no borderline points. Skipping.\n",
      "└ @ Imbalance ~/.julia/packages/Imbalance/knJL1/src/oversampling_methods/borderline_smote1/borderline_smote1.jl:67\n",
      "\rEvaluating over 5 folds:  80%[====================>    ]  ETA: 0:00:03\u001b[K[ Info: After filtering, the mapping from each class to number of borderline points is (\"virginica\" => 3, \"versicolor\" => 3).\n",
      "[ Info: After filtering, the mapping from each class to number of borderline points is (\"virginica\" => 3, \"versicolor\" => 3).\n",
      "\rEvaluating over 5 folds: 100%[=========================] Time: 0:00:11\u001b[K\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "PerformanceEvaluation object with these fields:\n  model, measure, operation,\n  measurement, per_fold, per_observation,\n  fitted_params_per_fold, report_per_fold,\n  train_test_rows, resampling, repeats\nExtract:\n┌────────────┬──────────────┬─────────────┐\n│\u001b[22m measure    \u001b[0m│\u001b[22m operation    \u001b[0m│\u001b[22m measurement \u001b[0m│\n├────────────┼──────────────┼─────────────┤\n│ Accuracy() │ predict_mode │ 0.99        │\n└────────────┴──────────────┴─────────────┘\n┌────────────────────────────┬─────────┐\n│\u001b[22m per_fold                   \u001b[0m│\u001b[22m 1.96*SE \u001b[0m│\n├────────────────────────────┼─────────┤\n│ [1.0, 1.0, 0.95, 1.0, 1.0] │ 0.0219  │\n└────────────────────────────┴─────────┘\n"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "cell_type": "code",
   "source": [
    "mach = machine(pipeline, X, y)\n",
    "fit!(mach)\n",
    "cv=CV(nfolds=5)\n",
    "evaluate!(mach, resampling=cv, measure=accuracy)"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  },
  "kernelspec": {
   "name": "julia-1.10",
   "display_name": "Julia 1.10.3",
   "language": "julia"
  }
 },
 "nbformat": 4
}
